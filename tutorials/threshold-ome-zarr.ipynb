{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99631be3",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "You are encouraged to experiment with the code, run it on your own data, and exchange knowledge with other participants. The purpose is to familiarise yourself with chunked pyramidal image files.\n",
    "\n",
    "If you don't have your own data, use the result of the `convert-tiff-to-ome-zarr.ipynb`, an OME-zarr file called `chunked_pyramidal_tibia`. It is a microCT scan of a mouse shin bone. As part of this tutorial, you will read in the OME-zarr file, and threshold it in-place.\n",
    "\n",
    "To get a visual representation of the chunks of the file, you will give each thresholded chunk a different label.\n",
    "\n",
    "The data is relatively small (~250 MB) - to make this tutorial run fast, but in \"the wild\" the techniques shown here are mostly useful for large data, that doesn't fit into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8468dd50",
   "metadata": {},
   "source": [
    "## Opening the zarr Group\n",
    "\n",
    "First, we open the `zarr` Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb6fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import zarr\n",
    "\n",
    "path = Path(\"/Volumes/T7/tibiae/pyramidal_chunked_tibia\")\n",
    "assert path.exists()\n",
    "zarr_group = zarr.open(path, mode=\"r+\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb3318",
   "metadata": {},
   "source": [
    "Next, we use `ome_zarr_models` to check the file for validity and explore it's metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_zarr_models import open_ome_zarr\n",
    "\n",
    "ome_zarr_group = open_ome_zarr(zarr_group)\n",
    "print(f\"Type of the dataset: {type(ome_zarr_group)}\")\n",
    "print(f\"OME-Zarr version: {ome_zarr_group.ome_zarr_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0143e15",
   "metadata": {},
   "source": [
    "Then, we create an OME-zarr Image from the `zarr` group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_zarr_models.v04 import Image\n",
    "\n",
    "ome_zarr_image = Image.from_zarr(zarr_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a764293",
   "metadata": {},
   "source": [
    "We can now access the various levels of the pyramid through the OME-zarr image metadata. Let's access level 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b7a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metadata = ome_zarr_image.attributes\n",
    "zarr_array = zarr_group[metadata.multiscales[0].datasets[0].path]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0e739a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_shape = zarr_array.chunks\n",
    "zarr_array_shape = zarr_array.shape\n",
    "\n",
    "color_index=1\n",
    "for i in range(0, zarr_array_shape[0], chunk_shape[0]):\n",
    "    for j in range(0, zarr_array_shape[1], chunk_shape[1]):\n",
    "        for k in range(0, zarr_array_shape[2], chunk_shape[2]):\n",
    "            chunk = zarr_array[\n",
    "                i:i+chunk_shape[0],\n",
    "                j:j+chunk_shape[1],\n",
    "                k:k+chunk_shape[2]\n",
    "            ]\n",
    "            # threshold chunk\n",
    "            chunk = (chunk > 50) \n",
    "\n",
    "            # give chunk a new index\n",
    "\n",
    "            chunk = chunk * color_index\n",
    "            zarr_array[\n",
    "                i:i+chunk_shape[0],\n",
    "                j:j+chunk_shape[1],\n",
    "                k:k+chunk_shape[2]    \n",
    "            ] = chunk\n",
    "\n",
    "            # update color to the next index\n",
    "            # the data is unsigned int 8\n",
    "            # so we repeat colours after reaching 255 chunks\n",
    "            color_index = (color_index+1)%256\n",
    "            if color_index == 0:\n",
    "                color_index = color_index+1\n",
    "            print(f\"Thresholded chunk at ({i}, {j}, {k})\")\n",
    "            print(f\"colour: {color_index}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28893a8d",
   "metadata": {},
   "source": [
    "Finally, we have to update the levels higher up the pyramid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fed828",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for d in [0,1,2]:\n",
    "    level_d_array = zarr_group[ome_zarr_image.attributes.multiscales[0].datasets[d].path]\n",
    "    level_d_array[:] = zarr_array[::2**d, ::2**d, ::2**d]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c328ad",
   "metadata": {},
   "source": [
    "Finally, we can visualise the result in `napari`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b721d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.open(path, plugin=\"napari-ome-zarr\")\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cc9f6c",
   "metadata": {},
   "source": [
    "Right-click on the layer, and hit convert to Labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a562b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-imaging-data-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
