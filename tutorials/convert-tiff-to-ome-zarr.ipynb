{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15739c1e",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "You are encouraged to play with the code, run it on your own data, and exchange knowledge with other participants.\n",
    "\n",
    "If you don't have your own data, you can use the `tibia.tiff` provided. The data is of a CT scan of a mouse shin bone (\"tibia\"), and is courtesy of Mark Hopkinson (Royal Veterinary College). As part of the tutorial, you will convert this 3D image stack to a OME-zarr, a chunked pyramidal file format. The data is relatively small (~250 MB) - to make this tutorial run fast, but in \"the wild\" the techniques shown here are mostly useful for large data, that doesn't fit into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6b5f6",
   "metadata": {},
   "source": [
    "## Reading the TIFF data\n",
    "\n",
    "In a first step, we read in the TIFF data with `bioio` and its `tifffile` reader plugin - this will work well for simple and small TIFF files like the tibia scan, but it might fail for larger formats or folders of 2D tiffs - see the Advanced tab for solution strategies for this. Make sure to update the local file path to point to the right place.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>Advanced: `bioio` readers and `dask`</summary>\n",
    "\n",
    "* If you'd like to try this on proprietary data, check the [`bioio` website for an appropriate reader](https://bioio-devs.github.io/bioio/OVERVIEW.html#reader-installation).\n",
    "* If you'd like to try this on large data, you will be [interested in `bioio.BioImage.get_image_dask_data`](https://bioio-devs.github.io/bioio/bioio.html#bioio.bio_image.BioImage.get_image_dask_data), which allows you to access [array data lazily through `dask`](https://docs.dask.org/en/stable/array.html).\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d095748",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bioio import BioImage, plugin_feasibility_report\n",
    "\n",
    "tiff_image_path = Path(\"/media/alessandro/T7/tibiae/acc52_10um.tif\")\n",
    "assert tiff_image_path.exists()\n",
    "print(plugin_feasibility_report(tiff_image_path))\n",
    "\n",
    "tiff_image = BioImage(tiff_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2718599",
   "metadata": {},
   "source": [
    "## Exploring the TIFF image\n",
    "\n",
    "In the next section, we can have a look at some of the image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2109db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tiff_image.dims)\n",
    "print(tiff_image.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9c5b2",
   "metadata": {},
   "source": [
    "For the example data, note the three spatial dimensions, and that there is just one timepoint and channel, and that the order of the dimensions is TCZYX.\n",
    "We also note that the metadata is dubious (this is common!): from the filename, we suspect that the pixel size is 10um, rather than 1.99 pixel.\n",
    "\n",
    "We might also want to plot some slices through the 3D image, and we see some cross-sections of a long bone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a397a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_central_slice(image_data, axis=0):\n",
    "    idx = image_data.shape[axis] // 2\n",
    "    central_slice = image_data.take(indices=idx, axis=axis)\n",
    "    plt.imshow(central_slice, cmap='gray')\n",
    "    plt.title(f'Central slice along axis {axis}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# the BioImage is 5D and follow TCZYX convention\n",
    "# we only want the spatial dimensions\n",
    "plot_central_slice(tiff_image.data[0,0], axis=0)\n",
    "plot_central_slice(tiff_image.data[0,0], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2576eb41",
   "metadata": {},
   "source": [
    "## Converting to chunked format (zarr)\n",
    "\n",
    "We have seen that we need to make decisions around storage location, chunk size and compression library and level to write chunked file formats. Let's see whether we can do each of these in Python below!\n",
    "\n",
    "First we remove the extra time and channel dimensions, for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tiff_image_3d_data = np.squeeze(tiff_image.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa76f1",
   "metadata": {},
   "source": [
    "Next, we specify the chunk size and the compression in an \"array specification\" (`ArraySpec`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_zarr.v2 import ArraySpec\n",
    "from numcodecs import Zstd\n",
    "\n",
    "array_spec = ArraySpec(\n",
    "    shape=tiff_image_3d_data.shape,\n",
    "    dtype=tiff_image_3d_data.dtype,\n",
    "    chunks=(64,64,64),\n",
    "    compressor=Zstd(level=5),\n",
    ")\n",
    "print(array_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f300a2",
   "metadata": {},
   "source": [
    "Now, we specify where we want to story the chunked file - by default, we'll make a folder next to the tiff file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67090539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "\n",
    "zarr_path = tiff_image_path.parent / \"chunked_tibia\"\n",
    "Path.mkdir(zarr_path, exist_ok=True)\n",
    "print(f\"Created a folder at {zarr_path}\")\n",
    "print(f\"Folder contents before creating zarr store {list(zarr_path.iterdir())}\")\n",
    "\n",
    "store = zarr.DirectoryStore(zarr_path)\n",
    "zarr_array = array_spec.to_zarr(store=store, path=\"/\")\n",
    "print(f\"Folder contents after creating zarr store {list(zarr_path.iterdir())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb605221",
   "metadata": {},
   "source": [
    "Note that `zarr_array` doesn't contain any pixel data yet (it's full of zeros) - it now just know where and how it should store data.\n",
    "So finally, we need to copy the data to the chunked array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zarr_array[:] = tiff_image_3d_data[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b2014",
   "metadata": {},
   "source": [
    "Let's see what's inside the zarr folder now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6f9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Folder contents after copying pixel data into zarr {list(zarr_path.iterdir())}\")\n",
    "print(f\"There are {len(list(zarr_path.iterdir()))-2} data subfolders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748b983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4d30e22",
   "metadata": {},
   "source": [
    "Can you explain the number of subfolders?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db55306",
   "metadata": {},
   "source": [
    "# Converting to pyramidal file format (OME-zarr)\n",
    "\n",
    "Now we can work on adding lower levels of resolution to the array, and specifying metadata. First, we re-use the same array specification as before, and specity voxel size, units and image name. We also specify that the current array is level 0 of the pyramid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa36db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ome_zarr_models.v04 import Image\n",
    "from ome_zarr_models.v04.axes import Axis\n",
    "\n",
    "voxel_size = 10\n",
    "ome_zarr_image = Image.new(\n",
    "    array_specs = [ArraySpec.from_array(zarr_array)],\n",
    "    paths = [\"level0\"],\n",
    "    axes = [\n",
    "        Axis(name=\"z\", type=\"space\", unit=\"um\"),\n",
    "        Axis(name=\"y\", type=\"space\", unit=\"um\"),\n",
    "        Axis(name=\"x\", type=\"space\", unit=\"um\")\n",
    "    ],\n",
    "    global_scale = [voxel_size, voxel_size, voxel_size],\n",
    "    scales = [[1, 1, 1]],\n",
    "    translations = [[0, 0, 0]],\n",
    "    name = \"mouse tibia\",\n",
    ")\n",
    "print(ome_zarr_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65e13ce",
   "metadata": {},
   "source": [
    "Now we add a new storage location (\"store\") for the pyramidal file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ome_zarr_path = tiff_image_path.parent / \"pyramidal_chunked_tibia\"\n",
    "ome_store = zarr.DirectoryStore(ome_zarr_path)\n",
    "ome_group = ome_zarr_image.to_zarr(ome_store, path='', overwrite=True)\n",
    "print(ome_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221c541",
   "metadata": {},
   "source": [
    "The code to access the array is quite complicated - we need to fill it with values again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "level0_array = ome_group[ome_zarr_image.attributes.multiscales[0].datasets[0].path]\n",
    "level0_array[:] = zarr_array[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd4dca4",
   "metadata": {},
   "source": [
    "Now let's create more levels by downsampling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a56124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "full_res_spec = ArraySpec.from_array(zarr_array)\n",
    "print(\"Original array specification: \", full_res_spec)\n",
    "\n",
    "downsample_levels = [0, 1, 2]\n",
    "downsampled_specs = [\n",
    "    full_res_spec.model_copy(\n",
    "        update={\"shape\": tuple(math.ceil(i / 2**d) for i in full_res_spec.shape)\n",
    "    }) for d in downsample_levels\n",
    "]\n",
    "print(\"Downsampled array specifications: \", downsampled_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ome_zarr_image = Image.new(\n",
    "    array_specs = downsampled_specs,\n",
    "    paths = [f\"level{d}\" for d in downsample_levels],\n",
    "    axes = [\n",
    "        Axis(name=\"x\", type=\"space\", unit=\"um\"),\n",
    "        Axis(name=\"y\", type=\"space\", unit=\"um\"),\n",
    "        Axis(name=\"z\", type=\"space\", unit=\"um\")\n",
    "    ],\n",
    "    global_scale = [voxel_size, voxel_size, voxel_size],\n",
    "    scales = [[2**d, 2**d, 2**d] for d in downsample_levels],\n",
    "    translations = [[0, 0, 0] for d in downsample_levels],\n",
    "    name = \"mouse tibia\"\n",
    ")\n",
    "print(ome_zarr_image)\n",
    "\n",
    "ome_group = ome_zarr_image.to_zarr(ome_store, path='', overwrite=True)\n",
    "print(ome_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e87657",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in downsample_levels:\n",
    "    level_d_array = ome_group[ome_zarr_image.attributes.multiscales[0].datasets[d].path]\n",
    "    level_d_array[:] = zarr_array[::2**d, ::2**d, ::2**d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc581a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.open(ome_zarr_path, plugin=\"napari-ome-zarr\")\n",
    "napari.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c471b0",
   "metadata": {},
   "source": [
    "Some areas for further exploration:\n",
    "* what parts of the code would you need to change if the data didn't fit in your memory\n",
    "* how could you change the chunk size?\n",
    "\n",
    "Or you can move on to the next tutorial, about reading and thresholding OME-zarr data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big-imaging-data-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
